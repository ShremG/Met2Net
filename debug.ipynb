{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelDuplicatingPixelUnshuffleUpSampleLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        factor: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.factor = factor\n",
    "        assert out_channels * factor**2 % in_channels == 0\n",
    "        self.repeats = out_channels * factor**2 // in_channels\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.repeat_interleave(self.repeats, dim=1)\n",
    "        x = F.pixel_shuffle(x, self.factor)\n",
    "        return x\n",
    "\n",
    "class PixelUnshuffleChannelAveragingDownSampleLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        factor: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.factor = factor\n",
    "        assert in_channels * factor**2 % out_channels == 0\n",
    "        self.group_size = in_channels * factor**2 // out_channels\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.pixel_unshuffle(x, self.factor)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.view(B, self.out_channels, self.group_size, H, W)\n",
    "        x = x.mean(dim=2)\n",
    "        return x\n",
    "    \n",
    "# Input parameters\n",
    "in_channels = 32\n",
    "out_channels = 64\n",
    "factor = 2\n",
    "\n",
    "# Create the layer\n",
    "downsample_layer = PixelUnshuffleChannelAveragingDownSampleLayer(in_channels, out_channels, factor)\n",
    "upsample_layer = ChannelDuplicatingPixelUnshuffleUpSampleLayer(out_channels,in_channels,factor)\n",
    "\n",
    "# Generate a random tensor with shape (B, in_channels, H, W)\n",
    "B, H, W = 1, 32, 64\n",
    "x = torch.randn(B, in_channels, H, W)\n",
    "\n",
    "# Forward pass through the layer\n",
    "output = downsample_layer(x)\n",
    "up = upsample_layer(output)\n",
    "\n",
    "# Print the output shape and content\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f'up shape:{up.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个需要梯度的张量\n",
    "src_tensor = torch.randn(3, 3, requires_grad=True)\n",
    "print(\"Source tensor requires_grad:\", src_tensor.requires_grad)  # True\n",
    "\n",
    "# 创建一个不需要梯度的张量\n",
    "target_tensor = torch.randn(3, 3, requires_grad=False)\n",
    "print(\"Target tensor requires_grad before:\", target_tensor.requires_grad)  # False\n",
    "\n",
    "# 将src_tensor赋值给target_tensor\n",
    "target_tensor = src_tensor  # 使用 clone 方法复制数据\n",
    "print(\"Target tensor requires_grad after:\", target_tensor.requires_grad)  # True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建一个 32x64 的随机图像\n",
    "image = np.random.rand(32, 64)\n",
    "\n",
    "# 计算图像的均值\n",
    "mean_value = np.mean(image)\n",
    "\n",
    "# 将图像分为 2x2 块\n",
    "blocks = image.reshape(16, 2, 32, 2).swapaxes(1, 2)\n",
    "\n",
    "# 总块数\n",
    "total_blocks = 16 * 32\n",
    "\n",
    "# 计算需要替换的块数\n",
    "num_blocks_to_replace = int(total_blocks * 0.3)\n",
    "\n",
    "# 随机选择块\n",
    "indices_to_replace = np.random.choice(total_blocks, num_blocks_to_replace, replace=False)\n",
    "\n",
    "# 将选中的块的所有值设置为均值\n",
    "for idx in indices_to_replace:\n",
    "    row = idx // 32\n",
    "    col = idx % 32\n",
    "    blocks[row, col, :, :] = mean_value\n",
    "\n",
    "# 重新组合图像\n",
    "masked_image = blocks.swapaxes(1, 2).reshape(32, 64)\n",
    "\n",
    "# 显示结果（使用 matplotlib 展示图像）\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(masked_image, cmap='gray')\n",
    "plt.title(\"Masked Image\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mask_replace_blocks(tensor):\n",
    "    # Calculate the mean of each channel across the entire batch\n",
    "    channel_means = tensor.mean(dim=(0, 1, -2, -1), keepdim=True)\n",
    "\n",
    "    # Get basic dimensions of the tensor\n",
    "    b, t, c, h, w = tensor.shape\n",
    "\n",
    "    # Generate a random mask for 2x2 blocks\n",
    "    block_mask = torch.rand(b, t, c, h//2, w//2) < 0.3  # 30% probability\n",
    "\n",
    "    # Expand the block mask to cover the entire dimensions of the blocks\n",
    "    mask = block_mask.repeat(1, 1, 1, 2, 2)\n",
    "\n",
    "    # Broadcast the channel means across the tensor dimensions\n",
    "    channel_means_expanded = channel_means.repeat(b, t, 1, h, w)\n",
    "\n",
    "    # Apply the mask and replace the selected blocks\n",
    "    tensor[mask] = channel_means_expanded[mask]\n",
    "\n",
    "    return tensor, mask\n",
    "\n",
    "# Generate a sample tensor with dimensions (2, 3, 4, 32, 64)\n",
    "input_tensor = torch.rand(2, 3, 4, 32, 64)\n",
    "\n",
    "# Apply the mask replace function\n",
    "masked_tensor, mask = mask_replace_blocks(input_tensor.clone())\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(2 * 3 * 4, 3, figsize=(15, 60))\n",
    "\n",
    "for i in range(2):  # Batch size\n",
    "    for j in range(3):  # Time steps\n",
    "        for k in range(4):  # Channels\n",
    "            idx = i * 3 * 4 + j * 4 + k\n",
    "            # Original image\n",
    "            axs[idx, 0].imshow(input_tensor[i, j, k].numpy(), cmap='gray')\n",
    "            axs[idx, 0].axis('off')\n",
    "            axs[idx, 0].set_title(f'Original - Batch {i}, Time {j}, Channel {k}')\n",
    "\n",
    "            # Masked image\n",
    "            axs[idx, 1].imshow(masked_tensor[i, j, k].numpy(), cmap='gray')\n",
    "            axs[idx, 1].axis('off')\n",
    "            axs[idx, 1].set_title(f'Masked - Batch {i}, Time {j}, Channel {k}')\n",
    "\n",
    "            # Masked image\n",
    "            axs[idx, 2].imshow(mask[i, j, k].numpy(), cmap='gray')\n",
    "            axs[idx, 2].axis('off')\n",
    "            axs[idx, 2].set_title(f'mask - Batch {i}, Time {j}, Channel {k}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义输入和输出索引范围\n",
    "idx_in = np.array([-3, -2, -1, 0])\n",
    "idx_out = np.array([1, 2, 3, 4])\n",
    "\n",
    "# 计算不重叠的步长\n",
    "sequence_length = len(idx_in) + len(idx_out)  # 总序列长度为8\n",
    "\n",
    "# 从索引11开始，以步长为 sequence_length 生成 valid_idx\n",
    "valid_idx = np.arange(3, 21 - 4, 1)\n",
    "valid_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openstl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
